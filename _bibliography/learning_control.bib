@inproceedings{bechtle_curious_2019,
	address = {Osaka, Japan},
	series = {Proceedings of {Machine} {Learning} {Research}},
	title = {Curious {iLQR}: {Resolving} {Uncertainty} in {Model}-based {RL}},
	volume = {100},
	url = {https://arxiv.org/abs/1904.06786},
	abstract = {Curiosity as a means to explore during reinforcement learning problems has recently become very popular. However, very little progress has been made in utilizing curiosity for learning control. In this work, we propose a model-based reinforcement learning (MBRL) framework that combines Bayesian modeling of the system dynamics with curious iLQR, an iterative LQR approach that considers model uncertainty. During trajectory optimization the curious iLQR attempts to minimize both the task-dependent cost and the uncertainty in the dynamics model. We demonstrate the approach on reaching tasks with 7-DoF manipulators in simulation and on a real robot. Our experiments show that MBRL with curious iLQR reaches desired end-effector targets more reliably and with less system rollouts when learning a new task from scratch, and that the learned model generalizes better to new reaching tasks.},
	booktitle = {Proceedings of the {Conference} on {Robot} {Learning}},
	author = {Bechtle, S and Lin, Y and Rai, A and Righetti, L and Meier, F},
	month = nov,
	year = {2019},
	keywords = {NYU, conference, website},
	pages = {162--171},
	file = {Bechtle et al. - 2019 - Curious iLQR Resolving Uncertainty in Model-based.pdf:/Users/righetti/Documents/literature/My papers/Bechtle et al. - 2019 - Curious iLQR Resolving Uncertainty in Model-based.pdf:application/pdf}
}


@inproceedings{bechtle_meta-learning_2021,
	address = {Milan},
	title = {Meta-learning via learned loss},
	url = {https://arxiv.org/abs/1906.05374},
	booktitle = {25th {International} {Conference} on {Pattern} {Recognition}},
	author = {Bechtle, S and Molchanov, A and Chebotar, Y and Grefenstette, E and Righetti, L and Sukhatme, G S and Meier, F},
	month = jan,
	year = {2021},
	keywords = {NYU, conference, website},
	file = {Bechtle et al. - 2021 - Meta-learning via learned loss.pdf:/Users/righetti/Documents/literature/My papers/Bechtle et al. - 2021 - Meta-learning via learned loss2.pdf:application/pdf}
}

@inproceedings{viereck_learning_2021,
	location = {Xi'an, China},
	title = {Learning a Centroidal Motion Planner for Legged Locomotion},
	url = {https://arxiv.org/abs/2011.02818},
	abstract = {Whole-body optimizers have been successful at automatically computing complex dynamic locomotion behaviors. However they are often limited to ofï¬‚ine planning as they are computationally too expensive to replan with a high frequency. Simpler models are then typically used for online replanning. In this paper we present a method to generate whole body movements in real-time for locomotion tasks. Our approach consists in learning a centroidal neural network that predicts the desired centroidal motion given the current state of the robot and a desired contact plan. The network is trained using an existing whole body motion optimizer. Our approach enables to learn with few training samples dynamic motions that can be used in a complete whole-body control framework at high frequency, which is usually not attainable with typical full-body optimizers. We demonstrate our method to generate a rich set of walking and jumping motions on a real quadruped robot.},
	eventtitle = {2021 {IEEE}-{RAS} International Conference on Robotics and Automation ({ICRA})},
	booktitle = {2021 {IEEE}-{RAS} International Conference on Robotics and Automation ({ICRA})},
	publisher = {{IEEE}},
	author = {Viereck, Julian and Righetti, Ludovic},
	date = {2021-05},
	keywords = {{NYU}, website, conference, {CPS}},
	file = {Viereck and Righetti - Learning a Centroidal Motion Planner for Legged Lo.pdf:/Users/righetti/Documents/literature/My papers/Viereck and Righetti - Learning a Centroidal Motion Planner for Legged Lo.pdf:application/pdf}
}